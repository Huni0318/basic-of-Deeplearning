{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = torch.FloatTensor([[.1, .2, .3],\n",
    "                            [.4, .5, .6],\n",
    "                            [.7, .8, .9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1734, 0.7527, 0.6142],\n",
       "        [0.5823, 0.8822, 0.6854],\n",
       "        [0.7639, 0.2124, 0.0032]], requires_grad=True)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand_like(target)\n",
    "# This means the final scalar will be differentiate by x.\n",
    "x.requires_grad = True\n",
    "# You can get gradient of x, after differentiation.\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1944, grad_fn=<MseLossBackward>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = F.mse_loss(x, target)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-th Loss: 1.1761e-01\n",
      "tensor([[0.1571, 0.6298, 0.5444],\n",
      "        [0.5418, 0.7973, 0.6664],\n",
      "        [0.7497, 0.3430, 0.2025]], requires_grad=True)\n",
      "2-th Loss: 7.1147e-02\n",
      "tensor([[0.1444, 0.5343, 0.4901],\n",
      "        [0.5103, 0.7312, 0.6517],\n",
      "        [0.7387, 0.4445, 0.3575]], requires_grad=True)\n",
      "3-th Loss: 4.3040e-02\n",
      "tensor([[0.1346, 0.4600, 0.4478],\n",
      "        [0.4858, 0.6798, 0.6402],\n",
      "        [0.7301, 0.5235, 0.4780]], requires_grad=True)\n",
      "4-th Loss: 2.6036e-02\n",
      "tensor([[0.1269, 0.4022, 0.4150],\n",
      "        [0.4667, 0.6399, 0.6313],\n",
      "        [0.7234, 0.5850, 0.5718]], requires_grad=True)\n",
      "5-th Loss: 1.5750e-02\n",
      "tensor([[0.1209, 0.3573, 0.3894],\n",
      "        [0.4519, 0.6088, 0.6243],\n",
      "        [0.7182, 0.6327, 0.6447]], requires_grad=True)\n",
      "6-th Loss: 9.5280e-03\n",
      "tensor([[0.1163, 0.3223, 0.3695],\n",
      "        [0.4403, 0.5846, 0.6189],\n",
      "        [0.7141, 0.6699, 0.7015]], requires_grad=True)\n",
      "7-th Loss: 5.7639e-03\n",
      "tensor([[0.1126, 0.2952, 0.3541],\n",
      "        [0.4314, 0.5658, 0.6147],\n",
      "        [0.7110, 0.6988, 0.7456]], requires_grad=True)\n",
      "8-th Loss: 3.4868e-03\n",
      "tensor([[0.1098, 0.2740, 0.3421],\n",
      "        [0.4244, 0.5512, 0.6114],\n",
      "        [0.7086, 0.7213, 0.7799]], requires_grad=True)\n",
      "9-th Loss: 2.1093e-03\n",
      "tensor([[0.1076, 0.2576, 0.3327],\n",
      "        [0.4190, 0.5398, 0.6089],\n",
      "        [0.7067, 0.7388, 0.8066]], requires_grad=True)\n",
      "10-th Loss: 1.2760e-03\n",
      "tensor([[0.1059, 0.2448, 0.3255],\n",
      "        [0.4148, 0.5310, 0.6069],\n",
      "        [0.7052, 0.7524, 0.8273]], requires_grad=True)\n",
      "11-th Loss: 7.7190e-04\n",
      "tensor([[0.1046, 0.2348, 0.3198],\n",
      "        [0.4115, 0.5241, 0.6054],\n",
      "        [0.7040, 0.7630, 0.8435]], requires_grad=True)\n",
      "12-th Loss: 4.6695e-04\n",
      "tensor([[0.1036, 0.2271, 0.3154],\n",
      "        [0.4089, 0.5187, 0.6042],\n",
      "        [0.7031, 0.7712, 0.8560]], requires_grad=True)\n",
      "13-th Loss: 2.8248e-04\n",
      "tensor([[0.1028, 0.2211, 0.3120],\n",
      "        [0.4069, 0.5146, 0.6033],\n",
      "        [0.7024, 0.7776, 0.8658]], requires_grad=True)\n",
      "14-th Loss: 1.7088e-04\n",
      "tensor([[0.1022, 0.2164, 0.3093],\n",
      "        [0.4054, 0.5113, 0.6025],\n",
      "        [0.7019, 0.7826, 0.8734]], requires_grad=True)\n",
      "15-th Loss: 1.0337e-04\n",
      "tensor([[0.1017, 0.2127, 0.3072],\n",
      "        [0.4042, 0.5088, 0.6020],\n",
      "        [0.7015, 0.7865, 0.8793]], requires_grad=True)\n",
      "16-th Loss: 6.2534e-05\n",
      "tensor([[0.1013, 0.2099, 0.3056],\n",
      "        [0.4033, 0.5069, 0.6015],\n",
      "        [0.7011, 0.7895, 0.8839]], requires_grad=True)\n",
      "17-th Loss: 3.7829e-05\n",
      "tensor([[0.1010, 0.2077, 0.3044],\n",
      "        [0.4025, 0.5053, 0.6012],\n",
      "        [0.7009, 0.7918, 0.8875]], requires_grad=True)\n",
      "18-th Loss: 2.2884e-05\n",
      "tensor([[0.1008, 0.2060, 0.3034],\n",
      "        [0.4020, 0.5041, 0.6009],\n",
      "        [0.7007, 0.7936, 0.8903]], requires_grad=True)\n",
      "19-th Loss: 1.3844e-05\n",
      "tensor([[0.1006, 0.2047, 0.3027],\n",
      "        [0.4015, 0.5032, 0.6007],\n",
      "        [0.7005, 0.7950, 0.8924]], requires_grad=True)\n",
      "20-th Loss: 8.3745e-06\n",
      "tensor([[0.1005, 0.2036, 0.3021],\n",
      "        [0.4012, 0.5025, 0.6006],\n",
      "        [0.7004, 0.7961, 0.8941]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "threshold = 1e-5\n",
    "learning_rate = 1.\n",
    "iter_cnt = 0\n",
    "\n",
    "while loss > threshold:\n",
    "    iter_cnt += 1\n",
    "    loss.backward() # Calculate gradients.\n",
    "    \n",
    "    x = x - learning_rate*x.grad\n",
    "    \n",
    "    x.detach_() # 다음 x랑 연관 끊어준다.\n",
    "    x.requires_grad_(True)\n",
    "    \n",
    "    loss = F.mse_loss(x, target)\n",
    "    \n",
    "    print('%d-th Loss: %.4e' % (iter_cnt,loss))\n",
    "    print(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
